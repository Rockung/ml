{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Negative sample for word2vec\n",
    "Compute cost, gradients for negative-sample in word2vec model\n",
    "* parameters: predicted, outputVectors, target, indices\n",
    "* target, indices are the indices into outputVectors\n",
    "* K is the length of indices\n",
    "\n",
    "\\begin{align}\n",
    "J_{neg-sample}(o, v_{c}, U) & = -\\log(\\delta(u_{o}^\\top v_{c}) - \\sum_{k=1}^{K} \\log(\\delta(-u_{k}^\\top v_{c})) \\\\\n",
    "\\frac {\\partial{J}} {\\partial{v_{c}}} & = (\\delta(u_{o}^\\top v_{c})-1) u_{o} - \\sum_{k=1}^{K} (\\delta(-u_{k}^\\top v_{c})-1) u_{k} \\\\\n",
    "\\frac {\\partial{J}} {\\partial{u_{o}}} & = (\\delta(u_{o}^\\top v_{c})-1) v_{c} \\\\\n",
    "\\frac {\\partial{J}} {\\partial{u_{k}}} & = (\\delta(u_{k}^\\top v_{c})-1) v_{c}, \\quad \\text {for all}\\; k = 1,2,\\dots, K\n",
    "\\end{align}\n",
    "\n",
    "In the following code, **predicted** is vector $v_{c}$, **outputVectors** is matrix $U$, **target** is subscript $o$, **cost** is $J_{neg-sample}(o, v_{c}, U)$, **gradPred** is $\\frac {\\partial{J}} {\\partial{v_{c}}}$, and **grad** are $\\frac {\\partial{J}} {\\partial{u_{o}}}$ and $\\frac {\\partial{J}} {\\partial{u_{k}}}$ ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from q2_sigmoid import sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = np.array([0.26726124, 0.53452248, 0.80178373])\n",
    "predicted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputVectors = np.array([\n",
    "       [0.26726124, 0.53452248, 0.80178373],\n",
    "       [0.45584231, 0.56980288, 0.68376346],\n",
    "       [0.50257071, 0.57436653, 0.64616234],\n",
    "       [0.52342392, 0.57576631, 0.62810871]])\n",
    "outputVectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target, indices are the indices into outputVectors\n",
    "# make sure K < len(outputVectors) and indices are not equal to target\n",
    "target, indices = 1, [0, 2]\n",
    "K = len(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradPred = np.zeros(predicted.shape)\n",
    "gradPred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad = np.zeros(outputVectors.shape)\n",
    "grad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.dot(outputVectors[target], predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_sigmoid = sigmoid(np.dot(outputVectors[target], predicted))\n",
    "out_sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = -np.log(out_sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputVectors[target].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(out_sigmoid - 1) * outputVectors[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradPred += (out_sigmoid - 1) * outputVectors[target]\n",
    "gradPred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(out_sigmoid - 1) * predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad[target] += (out_sigmoid - 1) * predicted\n",
    "grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(K):\n",
    "    idx = indices[k]\n",
    "    out_sigmoid = sigmoid(-np.dot(outputVectors[idx], predicted))\n",
    "    \n",
    "    cost -= np.log(out_sigmoid)\n",
    "    gradPred -= (out_sigmoid - 1) * outputVectors[idx]\n",
    "    grad[idx] -= (out_sigmoid - 1) * predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradPred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
