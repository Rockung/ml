{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Decision Tree Learning](https://en.wikipedia.org/wiki/Decision_tree_learning)\n",
    "\n",
    "Decision tree learning uses a decision tree as a model to predict an observation of some attributes.\n",
    "\n",
    "* Classification tree analysis is when the predicted outcome is the class to which the data belongs.\n",
    "* Regression tree analysis is when the predicted outcome can be considered a real number (e.g. the price of a house, or a patient's length of stay in a hospital).\n",
    "\n",
    "Data comes in records of the form:\n",
    "\n",
    "\\\\((x, Y)=(x_{1},x_{2},x_{3},...,x_{k},Y)\\\\)\n",
    "\n",
    "The dependent variable, \\\\(Y\\\\), is the target variable that we are trying to understand, classify or generalize. The vector x is composed of the features, \\\\(x_1, x_2, x_3\\\\) etc., that are used for that task.\n",
    "\n",
    "There are many specific decision-tree algorithms. Notable ones include:\n",
    "\n",
    "* ID3 (Iterative Dichotomiser 3)\n",
    "* C4.5 (successor of ID3)\n",
    "* CART (Classification And Regression Tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [ID3 algorithm](https://en.wikipedia.org/wiki/ID3_algorithm)\n",
    "In decision tree learning, ID3 (Iterative Dichotomiser 3) is an algorithm invented by Ross Quinlan used to generate a decision tree from a dataset. ID3 is the precursor to the C4.5 algorithm, and is typically used in the machine learning and natural language processing domains.\n",
    "\n",
    "Let's use [the code](https://github.com/Claygirl/decision-trees) to learn the algorithm. [This code](https://github.com/Erikfather/Decision_tree-python) is also very useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "\n",
    "    with open(filename, 'r') as csvfile:\n",
    "        datareader = csv.reader(csvfile, delimiter=',')\n",
    "        headers = next(datareader)\n",
    "        metadata = []\n",
    "        traindata = []\n",
    "        for name in headers:\n",
    "            metadata.append(name)\n",
    "            \n",
    "        for row in datareader:\n",
    "            traindata.append(row)\n",
    "\n",
    "    return (metadata, traindata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata, traindata = read_data(\"data/playtennis.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata, traindata = read_data(\"data/stock.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, attribute):\n",
    "        self.attribute = attribute\n",
    "        self.children = []\n",
    "        self.answer = \"\"\n",
    "        \n",
    "    def __str__(self):\n",
    "        return self.attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(traindata)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = np.unique(data[:, 0])\n",
    "items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partition the data table into subtables by column value\n",
    "# parameters:\n",
    "#    data: the datatable\n",
    "#    col:  the column to split\n",
    "#    delete: whether to delete the column from the result\n",
    "# returns\n",
    "#    items: the column value set\n",
    "#    dict: the dictionary of subtables by items\n",
    "def subtables(data, col, delete):\n",
    "    dict = {}\n",
    "    items = np.unique(data[:, col])\n",
    "    count = np.zeros((items.shape[0], 1), dtype=np.int32)[:, 0]\n",
    "    \n",
    "    for x in range(items.shape[0]):\n",
    "        for y in range(data.shape[0]):\n",
    "            if data[y, col] == items[x]:\n",
    "                count[x] += 1\n",
    "                \n",
    "    for x in range(items.shape[0]):\n",
    "        dict[items[x]] = np.empty((count[x], data.shape[1]), dtype=\"|S32\")\n",
    "        pos = 0\n",
    "        for y in range(data.shape[0]):\n",
    "            if data[y, col] == items[x]:\n",
    "                dict[items[x]][pos] = data[y]\n",
    "                pos += 1       \n",
    "        if delete:\n",
    "            dict[items[x]] = np.delete(dict[items[x]], col, 1)\n",
    "        \n",
    "    return items, dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items, dict = subtables(data, 1, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict[items[2]][:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entropy\n",
    "Entropy \\\\(H(S)\\\\) is a measure of the amount of uncertainty in the data set \\\\(S\\\\).\n",
    "\n",
    "\\\\(H(S) = \\sum_{x \\in X }-p(x)\\log2_{p(x)}\\\\)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the entropy of a collection\n",
    "def entropy(S):\n",
    "    X = np.unique(S)\n",
    "\n",
    "    if X.size == 1:\n",
    "        return 0\n",
    "    \n",
    "    probs = np.zeros((X.shape[0], 1))[:, 0]\n",
    "    sums = 0\n",
    "    \n",
    "    for x in range(X.shape[0]):\n",
    "        probs[x] = sum(S == X[x]) / (S.size * 1.0)\n",
    "\n",
    "    for p in probs:\n",
    "        sums += (-p) * math.log(p, 2)\n",
    "    return sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = data[:, -1]\n",
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = np.sum(S == 'yes') / (S.size * 1.0)\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "9.0 / 14 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy(data[:, -1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Information Gain\n",
    "\n",
    "Information gain \\\\(IG(A)\\\\) is the measure of the difference in entropy from before to after the set \\\\(S\\\\) is split on an attribute \\\\(A\\\\). In other words, how much uncertainty in \\\\(S\\\\) was reduced after splitting set \\\\(S\\\\) on attribute \\\\(A\\\\).\n",
    "\n",
    "\\\\(IG(S,A) = H(S) - H(S,A) \\\\)\n",
    "\n",
    "\\\\(H(S,A) = \\sum_{t \\in T} p(t) H(t)\\\\)\n",
    "\n",
    "* \\\\(H(S)\\\\) - Entropy of set \\\\(S\\\\)\n",
    "* \\\\(T\\\\) - The subsets created from splitting set \\\\(S\\\\) by attribute \\\\(A\\\\) such that \\\\(S = \\cup_{t \\in T} t\\\\)\n",
    "* \\\\(p(t)\\\\) - The propotion of # of elements in \\\\(t\\\\) to # of elements in \\\\(S\\\\)\n",
    "* \\\\(H(t)\\\\) - Entropy of set \\\\(t\\\\)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gain_ratio(data, col):\n",
    "    # items in X as keys in T\n",
    "    X, T = subtables(data, col, delete=False) \n",
    "\n",
    "    total_size = data.shape[0]\n",
    "    entropies = np.zeros((X.shape[0], 1))[:, 0]\n",
    "    intrinsic = np.zeros((X.shape[0], 1))[:, 0]\n",
    "    \n",
    "    for t in range(X.shape[0]):\n",
    "        pt = T[X[t]].shape[0] / (total_size * 1.0)\n",
    "        entropies[t] = pt * entropy(T[X[t]][:, -1])\n",
    "        intrinsic[t] = pt * math.log(pt, 2)\n",
    "        \n",
    "    return -(entropy(data[:, -1]) - sum(entropies)) / sum(intrinsic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gain_ratio(data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_node(data, metadata):\n",
    "    #TODO: \n",
    "\n",
    "    if (np.unique(data[:, -1])).shape[0] == 1:\n",
    "        node = Node(\"\")\n",
    "        node.answer = np.unique(data[:, -1])[0]\n",
    "        return node\n",
    "        \n",
    "    gains = np.zeros((data.shape[1] - 1, 1))\n",
    "    \n",
    "    for col in range(data.shape[1] - 1):\n",
    "        gains[col] = gain_ratio(data, col)\n",
    "        \n",
    "    split = np.argmax(gains)\n",
    "    \n",
    "    node = Node(metadata[split])    \n",
    "    metadata = np.delete(metadata, split, 0)    \n",
    "    \n",
    "    items, dict = subtables(data, split, delete=True)\n",
    "    \n",
    "    for x in range(items.shape[0]):\n",
    "        child = create_node(dict[items[x]], metadata)\n",
    "        node.children.append((items[x], child))\n",
    "    \n",
    "    return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def empty(size):\n",
    "    s = \"\"\n",
    "    for x in range(size):\n",
    "        s += \"   \"\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tree(node, level):\n",
    "    if node.answer != \"\":\n",
    "        print(empty(level), node.answer)\n",
    "        return\n",
    "        \n",
    "    print(empty(level), node.attribute)\n",
    "    \n",
    "    for value, n in node.children:\n",
    "        print(empty(level + 1), value)\n",
    "        print_tree(n, level + 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(traindata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node = create_node(data, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_tree(node, 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
