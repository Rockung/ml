{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Gaussian Naive Bayes](https://en.wikipedia.org/wiki/Naive_Bayes_classifier#Gaussian_naive_Bayes)\n",
    "\n",
    "* https://github.com/DTU-CS101/ML-TUTORIAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadCSV(filename):\n",
    "    with open(filename,\"r\") as csvfile:\n",
    "        lines = csv.reader(csvfile)\n",
    "        dataset = list(lines)\n",
    "        for i in range(len(dataset)):\n",
    "            dataset[i] = [float(x)for x in dataset[i]]\n",
    "    return dataset    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = loadCSV('data/pima-indians-diabetes.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitDataset(dataset, split_ratio):\n",
    "    '''\n",
    "    function to split dataset into test data and training data \n",
    "    according to the specified split ratio\n",
    "    '''\n",
    "    trainsize = int(len(dataset)*(split_ratio))\n",
    "    trainset = []\n",
    "    copy = list(dataset)\n",
    "\n",
    "    while len(trainset) < trainsize:\n",
    "        index= random.randrange(len(copy))\n",
    "        trainset.append(copy.pop(index))\n",
    "    return trainset, copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset, testset = splitDataset(dataset, 0.67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trainset), len(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separateByClass(dataset):\n",
    "    '''\n",
    "    function to separate the passed dataset according to \n",
    "    classvalue(0 or 1)\n",
    "    A dictionary with keys 0 and 1 is created, where each \n",
    "    key corrrespoondsto a list of rows of passed dataset.\n",
    "    '''\n",
    "    separated = {}\n",
    "    for i in range(len(dataset)):\n",
    "        vector = dataset[i]\n",
    "        # vector[-1] is the class value(0 or 1)\n",
    "        if vector[-1] not in separated:\n",
    "            separated[vector[-1]] = []\n",
    "        separated[vector[-1]].append(vector)\n",
    "    return separated  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "max([ testset[i][-1] for i in range(len(testset)) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "separated = separateByClass(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = [ attribute for attribute in zip(*dataset) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset[0]), len(attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset), len(attributes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(numbers):\n",
    "    '''\n",
    "    function to find mean of numbers present in the passed list\n",
    "    '''\n",
    "    return float(sum(numbers))/len(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(attributes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stddev(numbers):\n",
    "    '''\n",
    "    function to find 'sample standard deviation' of the numbers\n",
    "    in the passed list\n",
    "    '''\n",
    "    u = mean(numbers)\n",
    "    var = float(sum([(x-u)**2 for x in numbers]))/(len(numbers) - 1) \n",
    "    return math.sqrt(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stddev(attributes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(dataset):\n",
    "    '''\n",
    "    function to summarize the dataset stats.\n",
    "    mean and stddev of a complete column is calculated and stored as\n",
    "    a tuple in a list.\n",
    "    '''\n",
    "    #zip(*dataset) lets you access the data column-wise\n",
    "    summaries = [(mean(attr), stddev(attr)) for attr in zip(*dataset)] \n",
    "    #deleting the stats tuple for class variabe\n",
    "    del summaries[-1]\n",
    "    return summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarizeByClass(dataset):\n",
    "    '''\n",
    "    function to generate summaries dictonary for 0 and 1 classvalue.\n",
    "    '''\n",
    "    separated = separateByClass(dataset)\n",
    "    summaries = {}\n",
    "    for classValue, instances in separated.items():\n",
    "        summaries[classValue] = summarize(instances)\n",
    "    return summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summaries = summarizeByClass(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(summaries), len(summaries[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateProbability(x, mean, stdev):\n",
    "    '''\n",
    "    function to calculate probability using gaussian probability\n",
    "    density function\n",
    "    '''\n",
    "    exponent = math.exp(-((math.pow(x-mean,2))/(2*stdev**2)))\n",
    "    return (1.0/(math.sqrt(math.pi*2)*stdev)*exponent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculateProbability(3.5, summaries[0][0][0], summaries[0][0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classProb(summaries, inputVec):\n",
    "    '''\n",
    "    function to generate class probabilities, i.e probaility with\n",
    "    which our input set belongs to classvalue 0 or 1.\n",
    "    '''\n",
    "    probabilities = {}\n",
    "    for classValue, classSum in summaries.items():\n",
    "        probabilities[classValue] = 1\n",
    "        for i in range(len(classSum)):\n",
    "            mean, stddev = classSum[i]\n",
    "            x = inputVec[i]\n",
    "            #multiplying together the attribute probabilities.\n",
    "            probabilities[classValue] *= calculateProbability(x, mean, stddev)\n",
    "    return probabilities        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[classValue for classValue, classSum in summaries.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classProb(summaries, testset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(summaries, inputVec):\n",
    "    '''\n",
    "    function to predict a classvalue for the passed testcase\n",
    "    here we look for the largest probability and return the \n",
    "    associated class(Label).\n",
    "    '''\n",
    "    prob = classProb(summaries, inputVec)\n",
    "    bestLabel, bestProb = None, -1\n",
    "\n",
    "    for classValue, probability in prob.items():\n",
    "        if bestLabel is None or probability > bestProb:\n",
    "            bestLabel = classValue\n",
    "            bestProb = probability\n",
    "    return bestLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [i for i, val in enumerate(testset) if val[-1] == 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predict(summaries, testset[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPredictions(summaries, testset):\n",
    "    '''\n",
    "    function to generate predictions for our each row(instance)\n",
    "    of our dataset\n",
    "    '''\n",
    "    predictions = []\n",
    "    for i in range(len(testset)):\n",
    "        result = predict(summaries, testset[i])\n",
    "        predictions.append(result)\n",
    "    return predictions    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = getPredictions(summaries, testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAccuracy(testset, predictions):\n",
    "    '''\n",
    "    function to calculate accuracy by comparing actual classvalues\n",
    "    with the predicted classvalues\n",
    "    '''\n",
    "    correct= 0\n",
    "    for i in range(len(testset)):\n",
    "        if testset[i][-1] == predictions[i]:\n",
    "            correct += 1\n",
    "    return (correct/float(len(predictions)))*100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getAccuracy(testset, predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
